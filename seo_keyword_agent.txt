import os, json, base64, requests, pandas as pd
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from hdbscan import HDBSCAN

# 1️⃣  Config
load_dotenv()                                           # Carica .env
API_ROOT = "https://www.asidatamyte.it/wp-json/wp/v2/keyword_suggestion"
auth = base64.b64encode(f"{os.getenv('WP_USER')}:{os.getenv('WP_APP_PWD')}".encode()).decode()

# 2️⃣  Modelli
embedder = SentenceTransformer("mixedbread-ai/mxbai-embed-large-v1")

# 3️⃣  Carica le 26 pagine
df = pd.read_csv("pages.csv")

# 4️⃣  Ciclo per pagina
for _, row in df.iterrows():
    seed   = row["seed_topic"]
    page   = row["pagina"]
    seeds  = json.loads(row["keywords_di_partenza"])
    # …chiamata DataForSEO 'keywords_for_keywords/live' qui…
    keywords = ["demo", "keyword"]    # placeholder

    # Calcola embeddings e cluster
    emb = embedder.encode(keywords)
    labels = HDBSCAN(min_cluster_size=8).fit_predict(emb)

    # 5️⃣  Invio a WordPress
    for kw, lab in zip(keywords, labels):
        data = {
            "title": kw,
            "status": "publish",
            "fields": {
                "page": page,
                "cluster": int(lab),
                "intent": "informational",         # placeholder LLM
                "difficulty": 32,                  # placeholder API
                "opportunity": 68                  # placeholder formula
            }
        }
        r = requests.post(API_ROOT,
                          headers={"Authorization": f"Basic {auth}"},
                          json=data, timeout=30)
        r.raise_for_status()                       # → HTTP 201


import ast, json, pandas as pd

# ---------- 1️⃣  LEGGI IL CSV CON ENCODING SICURO ------------
df = pd.read_csv("pages.csv", encoding="utf-8")   # se UTF-8
# df = pd.read_csv("pages.csv", encoding="latin-1")  # fallback ANSI :contentReference[oaicite:0]{index=0}

for _, row in df.iterrows():
    raw = (row.get("keywords_di_partenza") or "[]").strip()

    # ---------- 2️⃣  VALIDAZIONE ROBUSTA DELLA CELLA JSON ----
    try:
        seeds = json.loads(raw)                               # preferito
    except json.JSONDecodeError:                              # :contentReference[oaicite:1]{index=1}
        try:
            seeds = ast.literal_eval(raw)                     # es.: ['kw1','kw2']
        except Exception:
            seeds = []

    # -> usa `seeds` come lista di keyword di partenza



from dataforseo_api3 import RestClient   # pip install dataforseo_api3
import os, time, requests, base64
from dotenv import load_dotenv
load_dotenv()

DFS_LOGIN = os.getenv("DFS_LOGIN")
DFS_PWD   = os.getenv("DFS_PWD")

client = RestClient(login=DFS_LOGIN, password=DFS_PWD)  # Basic Auth interno

def fetch_keywords(seed_list):
    """
    Ritorna volume, CPC, difficulty per ogni seed usando
    'keywords_data/google/keywords_for_keywords/live' :contentReference[oaicite:3]{index=3}
    """
    post_data = [{
        "keywords": seed_list[:200],        # max 200 / task
        "language_name": "Italian",
        "location_code": 2250              # Italy
    }]

    response = client.post("/v3/keywords_data/google/keywords_for_keywords/live", post_data)
    time.sleep(1)                          # best-practice DataForSEO :contentReference[oaicite:4]{index=4}
    results = response["tasks"][0]["result"][0]["items"]
    return results        # ogni item: keyword, search_volume, competition, cpc


def score(item):
    vol = item["search_volume"]
    kd  = int(float(item["competition"])*100)   # 0-100
    opp = round((vol*0.6 - kd*0.4) / 100, 2)    # esempio
    return kd, opp


# sopprime l'avviso 'force_all_finite' rinominato 'ensure_all_finite'
import warnings, sklearn
warnings.filterwarnings(
    "ignore",
    message=".*force_all_finite.*renamed to ensure_all_finite.*",
    category=FutureWarning
)  # :contentReference[oaicite:8]{index=8}